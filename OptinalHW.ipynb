{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sivarammandava/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sivarammandava/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Name: Sivaram Mandava\n",
    "# NetID: sxm169331\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv2D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "stopWords = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"You can't relate with them, hell you barely can understand them.  \"\n",
      " \"The instructions didn't explain that a microphone jack could be used.\"\n",
      " \"I liked the way Dustin Hoffman's character was ready to do just about everything to stay with his son.  \"\n",
      " 'I really loved the story line and the poler bear was kinda cute.But if anyone has a question about Fort Steele, just ask away:)  '\n",
      " 'Unfortunately, inexperience of direction meant that scene after scene passed with little in the way of dramatic tension or conflict.  '\n",
      " 'I love this device.'\n",
      " 'The headset fulfills my requirements so I am happy with my purchase.'\n",
      " 'I knew when I saw the film that more great things were to come from this gifted actor.  '\n",
      " \"There was a few pathetic attempts to give the characters some depth, but it didn't really work into the rest of the plot.  \"\n",
      " 'I recently had problems where I could not stay connected for more than 10 minutes before being disconnected.']\n",
      "[0 0 1 1 0 1 1 1 0 0]\n",
      "[\"I'd love to go back.\" 'stay away from this store, be careful.'\n",
      " 'I could care less... The interior is just beautiful.'\n",
      " 'O my gosh the best phone I have ever had.'\n",
      " 'We have gotten a lot of compliments on it.'\n",
      " \"Ordered burger rare came in we'll done.\"\n",
      " 'The decor is nice, and the piano music soundtrack is pleasant.'\n",
      " 'This is truly an art movie--it actually has a lot of art in it.  '\n",
      " 'Excellent product for the price.' 'This is a great little item.']\n",
      "[1 0 1 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Question-1.\n",
    "DF = pd.read_csv('train.csv')\n",
    "trainX = DF.loc[:, 'sentence'].values\n",
    "print(trainX[:10])\n",
    "trainY = DF.loc[:, 'label'].values\n",
    "print(trainY[:10])\n",
    "\n",
    "DF = pd.read_csv('test.csv')\n",
    "testX = DF.loc[:, 'sentence'].values\n",
    "print(testX[:10])\n",
    "testY = DF.loc[:, 'label'].values\n",
    "print(testY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trainY, density = True, color = 'purple')\n",
    "plt.xlabel('Train Data Labels')\n",
    "plt.ylabel('Label count')\n",
    "plt.show()\n",
    "plt.hist(testY, density = True, color = 'purple')\n",
    "plt.xlabel('Test Data Labels')\n",
    "plt.ylabel('Label count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if not word in stopWords]\n",
    "    return tokens\n",
    "\n",
    "vect = TfidfVectorizer(tokenizer=tokenize, use_idf=True)\n",
    "train_vector = vect.fit_transform(trainX)\n",
    "test_vector = vect.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes shows: 0.8018181818181818\n",
      "[[215  37]\n",
      " [ 72 226]]\n"
     ]
    }
   ],
   "source": [
    "Model = MultinomialNB()\n",
    "Model.fit(train_vector, trainY)\n",
    "predicted = Model.predict(test_vector)\n",
    "print(\"Naive Bayes shows:\", accuracy_score(predicted, testY))\n",
    "print(confusion_matrix(predicted, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.7818181818181819\n",
      "[[234  67]\n",
      " [ 53 196]]\n"
     ]
    }
   ],
   "source": [
    "Model = LogisticRegression(solver='lbfgs')\n",
    "Model.fit(train_vector, trainY)\n",
    "predicted = Model.predict(test_vector)\n",
    "print(\"Logistic Regression:\", accuracy_score(predicted, testY))\n",
    "print(confusion_matrix(predicted, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network ('For Relu'): 0.7636363636363637\n",
      "[[215  58]\n",
      " [ 72 205]]\n",
      "Neural Network ('FOr Identity'): 0.7454545454545455\n",
      "[[210  63]\n",
      " [ 77 200]]\n",
      "Neural Network ('For Logistic'): 0.7636363636363637\n",
      "[[215  58]\n",
      " [ 72 205]]\n",
      "Neural Network ('For TanH'): 0.7418181818181818\n",
      "[[210  65]\n",
      " [ 77 198]]\n"
     ]
    }
   ],
   "source": [
    "# Question-6.\n",
    "Model = MLPClassifier(activation='relu', max_iter=500)\n",
    "Model.fit(train_vector, trainY)\n",
    "predicted = Model.predict(test_vector)\n",
    "print(\"Neural Network ('For Relu'):\", accuracy_score(predicted, testY))\n",
    "print(confusion_matrix(predicted, testY))\n",
    "\n",
    "Model = MLPClassifier(activation='identity', max_iter=500)\n",
    "Model.fit(train_vector, trainY)\n",
    "predicted = Model.predict(test_vector)\n",
    "print(\"Neural Network ('FOr Identity'):\", accuracy_score(predicted, testY))\n",
    "print(confusion_matrix(predicted, testY))\n",
    "\n",
    "Model = MLPClassifier(activation='logistic', max_iter=500)\n",
    "Model.fit(train_vector, trainY)\n",
    "predicted = Model.predict(test_vector)\n",
    "print(\"Neural Network ('For Logistic'):\", accuracy_score(predicted, testY))\n",
    "print(confusion_matrix(predicted, testY))\n",
    "\n",
    "Model = MLPClassifier(activation='tanh', max_iter=500)\n",
    "Model.fit(train_vector, trainY)\n",
    "predicted = Model.predict(test_vector)\n",
    "print(\"Neural Network ('For TanH'):\", accuracy_score(predicted, testY))\n",
    "print(confusion_matrix(predicted, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe Various Results:\\nFor the Naive Bayes Confusion Matrix: [[215  37]\\n                              [ 72 226]]\\nFor the Naive Bayes Accuracy Score: 0.8018181818181818\\n\\nFor the Logistic Regression Confusion Matrix: [[234  67]\\n                                      [ 53 196]]\\nFOr the Logistic Regression Accuracy Score: 0.7818181818181819\\n\\n\\nNeural Networks: \\nFOr iterations = 200.\\n\\nFor the Neural Network Confusion Matrix: [[213  59]\\n                                 [ 74 204]]\\nFor the Neural Network ('FOr relu') Accuracy Score: 0.7581818181818182\\n\\nFor the Neural Network Confusion Matrix: [[211  64]\\n                                 [ 76 199]]\\nFor the Neural Network ('FOr identity') Accuracy Score: 0.7454545454545455\\n\\nFor the Neural Network Confusion Matrix: [[216  56]\\n                                 [ 71 207]]\\nFor the Neural Network ('For logistic') Accuracy Score: 0.769090909090909\\n\\nFor the Neural Network Confusion Matrix: [[210  64]\\n                                 [ 77 199]]\\nFor the Neural Network ('For tanh') Accuracy Score: 0.7436363636363637\\n\\n\\nFor iterations = 500\\nFor the Neural Network Confusion Matrix: [[213  58]\\n                                 [ 74 205]]\\nFor the Neural Network ('For relu') Accuracy Score: 0.76\\n\\nFor the Neural Network Confusion Matrix: [[212  64]\\n                                 [ 75 199]]\\nFor the Neural Network ('For the identity') Accuracy Score: 0.7472727272727273\\n\\nFor the Neural Network Confusion Matrix: [[216  59]\\n                                 [ 71 204]]\\nFor the Neural Network ('For the logistic') Accuracy Score: 0.7636363636363637\\n\\nFor the Neural Network Confusion Matrix: [[209  63]\\n                                 [ 78 200]]\\nFor the Neural Network ('For the tanh') Accuracy Score: 0.7436363636363637\\n\\n\\n\\nBased on this we can see that Naive Bayes gives us the best accuracy. It gives us the best ratio of true values \\nagainst the False values. As you can see the confusion matrix for most of them are similar. But when it comes to Naive Bayes and \\nLogistic Regression it is a little different. based on how you want the output, you should decide what method to follow. \\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question-7.\n",
    "'''\n",
    "The Various Results:\n",
    "For the Naive Bayes Confusion Matrix: [[215  37]\n",
    "                              [ 72 226]]\n",
    "For the Naive Bayes Accuracy Score: 0.8018181818181818\n",
    "\n",
    "For the Logistic Regression Confusion Matrix: [[234  67]\n",
    "                                      [ 53 196]]\n",
    "FOr the Logistic Regression Accuracy Score: 0.7818181818181819\n",
    "\n",
    "\n",
    "Neural Networks: \n",
    "FOr iterations = 200.\n",
    "\n",
    "For the Neural Network Confusion Matrix: [[213  59]\n",
    "                                 [ 74 204]]\n",
    "For the Neural Network ('FOr relu') Accuracy Score: 0.7581818181818182\n",
    "\n",
    "For the Neural Network Confusion Matrix: [[211  64]\n",
    "                                 [ 76 199]]\n",
    "For the Neural Network ('FOr identity') Accuracy Score: 0.7454545454545455\n",
    "\n",
    "For the Neural Network Confusion Matrix: [[216  56]\n",
    "                                 [ 71 207]]\n",
    "For the Neural Network ('For logistic') Accuracy Score: 0.769090909090909\n",
    "\n",
    "For the Neural Network Confusion Matrix: [[210  64]\n",
    "                                 [ 77 199]]\n",
    "For the Neural Network ('For tanh') Accuracy Score: 0.7436363636363637\n",
    "\n",
    "\n",
    "For iterations = 500\n",
    "For the Neural Network Confusion Matrix: [[213  58]\n",
    "                                 [ 74 205]]\n",
    "For the Neural Network ('For relu') Accuracy Score: 0.76\n",
    "\n",
    "For the Neural Network Confusion Matrix: [[212  64]\n",
    "                                 [ 75 199]]\n",
    "For the Neural Network ('For the identity') Accuracy Score: 0.7472727272727273\n",
    "\n",
    "For the Neural Network Confusion Matrix: [[216  59]\n",
    "                                 [ 71 204]]\n",
    "For the Neural Network ('For the logistic') Accuracy Score: 0.7636363636363637\n",
    "\n",
    "For the Neural Network Confusion Matrix: [[209  63]\n",
    "                                 [ 78 200]]\n",
    "For the Neural Network ('For the tanh') Accuracy Score: 0.7436363636363637\n",
    "\n",
    "\n",
    "\n",
    "Based on this we can see that Naive Bayes gives us the best accuracy. It gives us the best ratio of true values \n",
    "against the False values. As you can see the confusion matrix for most of them are similar. But when it comes to Naive Bayes and \n",
    "Logistic Regression it is a little different. based on how you want the output, you should decide what method to follow. \n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2198/2198 [==============================] - 0s 148us/step - loss: 2.0866 - accuracy: 0.4891\n",
      "550/550 [==============================] - 0s 94us/step\n",
      "Keras Sequential Model ('relu'): [1.2385457836497913, 0.5218181610107422]\n",
      "Epoch 1/1\n",
      "2198/2198 [==============================] - 0s 82us/step - loss: 7.4992 - accuracy: 0.5109\n",
      "550/550 [==============================] - 0s 55us/step\n",
      "Keras Sequential Model ('softmax'): [8.001162890520963, 0.4781818091869354]\n"
     ]
    }
   ],
   "source": [
    "Model = Sequential()\n",
    "Model.add(Dense(1, input_dim=4690))\n",
    "Model.add(Activation('relu'))\n",
    "Model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "Model.fit(train_vector, trainY)\n",
    "Score = Model.evaluate(test_vector, testY)\n",
    "print(\"Keras Sequential Model ('relu'):\", Score)\n",
    "\n",
    "Model = Sequential()\n",
    "Model.add(Dense(1, input_dim=4690))\n",
    "Model.add(Activation('softmax'))\n",
    "Model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "Model.fit(train_vector, trainY)\n",
    "Score = Model.evaluate(test_vector, testY)\n",
    "print(\"Keras Sequential Model ('softmax'):\", Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe have ran multiple models and we have noticed that this is similar to the ones in step 7. This is best seen in relu and Naive Bayes.\\nWe can see this in the COnfusion Matroix for it.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question-9\n",
    "'''\n",
    "We have ran multiple models and we have noticed that this is similar to the ones in step 7. This is best seen in relu and Naive Bayes.\n",
    "We can see this in the COnfusion Matroix for it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"You can't relate with them, hell you barely can understand them.  \"\n",
      " \"The instructions didn't explain that a microphone jack could be used.\"\n",
      " \"I liked the way Dustin Hoffman's character was ready to do just about everything to stay with his son.  \"\n",
      " 'I really loved the story line and the poler bear was kinda cute.But if anyone has a question about Fort Steele, just ask away:)  '\n",
      " 'Unfortunately, inexperience of direction meant that scene after scene passed with little in the way of dramatic tension or conflict.  '\n",
      " 'I love this device.'\n",
      " 'The headset fulfills my requirements so I am happy with my purchase.'\n",
      " 'I knew when I saw the film that more great things were to come from this gifted actor.  '\n",
      " \"There was a few pathetic attempts to give the characters some depth, but it didn't really work into the rest of the plot.  \"\n",
      " 'I recently had problems where I could not stay connected for more than 10 minutes before being disconnected.']\n",
      "[0 0 1 1 0 1 1 1 0 0]\n",
      "[\"I'd love to go back.\" 'stay away from this store, be careful.'\n",
      " 'I could care less... The interior is just beautiful.'\n",
      " 'O my gosh the best phone I have ever had.'\n",
      " 'We have gotten a lot of compliments on it.'\n",
      " \"Ordered burger rare came in we'll done.\"\n",
      " 'The decor is nice, and the piano music soundtrack is pleasant.'\n",
      " 'This is truly an art movie--it actually has a lot of art in it.  '\n",
      " 'Excellent product for the price.' 'This is a great little item.']\n",
      "[1 0 1 1 1 0 1 1 1 1]\n",
      "Keras Sequential Model ('relu') using keras_preprocessing text tokenizer: [8.001162890520963, 0.4781818091869354]\n",
      "Keras Sequential Model ('softmax') using keras_preprocessing text tokenizer:: [8.001162890520963, 0.4781818091869354]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DF = pd.read_csv('train.csv')\n",
    "trainX = DF.loc[:, 'sentence'].values\n",
    "print(trainX[:10])\n",
    "trainY = DF.loc[:, 'label'].values\n",
    "print(trainY[:10])\n",
    "\n",
    "DF = pd.read_csv('test.csv')\n",
    "testX = DF.loc[:, 'sentence'].values\n",
    "print(testX[:10])\n",
    "testY = DF.loc[:, 'label'].values\n",
    "print(testY[:10])\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = text_to_word_sequence(text)\n",
    "    tokens = [word for word in tokens if not word in stopWords]\n",
    "    return tokens\n",
    "\n",
    "vect = TfidfVectorizer(tokenizer=tokenize, use_idf=True)\n",
    "train_vector = vect.fit_transform(trainX)\n",
    "test_vector = vect.transform(testX)\n",
    "\n",
    "Model = Sequential()\n",
    "Model.add(Dense(1, input_dim=4581))\n",
    "Model.add(Activation('relu'))\n",
    "Model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"Keras Sequential Model ('relu') using keras_preprocessing text tokenizer:\", Score)\n",
    "\n",
    "Model = Sequential()\n",
    "Model.add(Dense(1, input_dim=4581))\n",
    "Model.add(Activation('softmax'))\n",
    "Model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"Keras Sequential Model ('softmax') using keras_preprocessing text tokenizer::\", Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 11\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plot the first image in the dataset\n",
    "plt.imshow(X_train[0])\n",
    "\n",
    "\n",
    "#check image shape\n",
    "X_train[0].shape\n",
    "\n",
    "#reshape data to fit model\n",
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "#one-hot encode target column\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
